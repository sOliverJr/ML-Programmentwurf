{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Programmentwurf\n",
    "\n",
    "> **Algorythmus**: Klassifikation\n",
    ">\n",
    "> **Datensatz**: Iris\n",
    ">\n",
    "> **Autor**: Oliver Seider\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Einlesen\n",
    "\n",
    "Der Datensatz wird mit Pandas eingelesen. Es werden zusätzlich Namen für die Spalten definiert, obwohl diese ab dem nächten Schritt nicht mehr von Relevanz sind.\n",
    "\n",
    "Anschließend wird der Datensatz mit Hilfe von *numpy* in ein zweidimensionales Array umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "headers = ['sepal length', 'sepal width', 'petal length', 'petal width', 'category']\n",
    "pandas_dataframe = pd.read_csv('iris.data', header=None, names=headers)\n",
    "\n",
    "array_2d = pandas_dataframe.to_numpy()\n",
    "\n",
    "# print(pandas_dataframe)\n",
    "# print(array_2d)\n",
    "print('There are {0} samples in the dataset'.format(len(array_2d)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umformen der Daten\n",
    "Das Zweidimensionale Daten-Array wird in einem nächten Schritt in Features und Kategorie aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array_2d = array_2d[:150,:4]\n",
    "category_array = array_2d[:150, 4:].reshape([150])\n",
    "\n",
    "# print(data_array_2d)\n",
    "# print(category_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufteilen der Daten in Lern- und Testdaten\n",
    "Der Test-Datensatz stellt 25 Prozent der Originaldaten dar. Bei der Aufspaltung wurde ein Zufallskoeffizient von 0 gewählt, was bedeutet dass immer die selbe Aufteilung ausgegeben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reshaped_data_train, reshaped_data_test, target_data_train, target_data_test = train_test_split(data_array_2d, category_array, test_size=0.25, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen des Modells\n",
    "In dem nächsten Schritt werden **KNeighborsClassifier** mit 0-20 *neigbors* erstellt und mit Hilfe des ***cross-validation*** Algorythmus von *sklearn* beweertet, um die beste Anzahl an *neighbours* herauszufinden.\n",
    "\n",
    "Durch den 'return_estimator=True' Parameter bei der *cross-validation* werden die *k* Modelle, die bei der *cross-validation* erstellt wurden, zurückgegeben.\n",
    "\n",
    "Erzielt die Anzahl an *neighbours* einen besseren durchschnittlichen Score in der *cross-validation*, wird das Modell geespeichert.\n",
    "\n",
    "Am Ende wird das beste Modell für den weiteren Verlauf mit den Trainings-Daten 'trainiert'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "best_model = [None, 0, 0]\n",
    "scores = []\n",
    "\n",
    "for n in range(1, 20):\n",
    "    model = KNeighborsClassifier(n_neighbors=n)\n",
    "    results = cross_validate(model, reshaped_data_train, target_data_train, cv=5, return_estimator=True)\n",
    "    average_score = np.mean(results['test_score'])\n",
    "    if average_score > best_model[1]:\n",
    "        best_model = [model, average_score, n]\n",
    "    scores.append(average_score)\n",
    "\n",
    "# print(best_model)\n",
    "print(f'The best average score ({best_model[1]}) is archived with {best_model[2]} neighbours.')\n",
    "best_model = best_model[0].fit(reshaped_data_train, target_data_train)\n",
    "# print(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testen des Modells\n",
    "Nun werden die Testdaten anhand des besten Modells klassifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Klassen-Angehörigkeit von jedem Datensatatz nach dem Modell\n",
    "y = best_model.predict(reshaped_data_test)\n",
    "\n",
    "# print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluierung des Modells\n",
    "In diesem letzten Schritt werden die Ergebnisse aus dem Vorherigen Schritt anhand von einem *Classification Report* und einer *Confusion Matrix* evaluiert.\n",
    "\n",
    "**Classification Report:**\n",
    "- *Precision*: Gibt an, wie viele der identifizierten Elemente *true positives* sind (true positives / [true positives + false positives]).\n",
    "- *Recall*: Gibt an, wie viele Elemente, die einer Klasse angehören, dieser auch zugeteilt wurden (true positives / [true positives + false negatives])\n",
    "- *F1-Score*: Harmonischer Mittelwert aus *Precision* und *Recall*\n",
    "- *Support*: Anzahl an Datensätzen, die zum Bestimmen der vorherigen Werte verwendet wurden.\n",
    "\n",
    "**Confusion Matrix:**\n",
    "Zweidimensionale Matrix, die für jede Klasse und deren Datensätze zeigt, wie häufig das Modell einen Datensatz einer Klasse zugeordnet hat. \n",
    "Dabei stellt jede Spalte eine Klasse und dessen Datensätze dar, während die Spalten angeben wie oft eine Datensatz dieser Klasse zugeordnet wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "print('Classification Report:')\n",
    "print(metrics.classification_report(target_data_test, y))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(target_data_test, y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der *Classification Report* zeigt, dass dieses Modell einen durchschnittlichen F1-Score von 0,97 erhält, was über 0,9 liegt und somit als sehr gut klassifiziert werden kann."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
